% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/HIP_eval.R
\name{HIP_test_eval}
\alias{HIP_test_eval}
\title{Evaluate model on test data}
\usage{
HIP_test_eval(data, res, fix_or_search, outcome_var=NULL)
}
\arguments{
\item{data}{data object such as from \code{generate_data} or \code{py_data} containing both X, Y data and X_test, Y_test data}

\item{res}{training result such as from \code{select_lambda} or \code{fixed_lambda}}

\item{fix_or_search}{string - 'fixed' for results from \code{fixed_lambda},
'search' for results from \code{select_lambda}}

\item{outcome_var}{string - label of outcome variable, if available}
}
\value{
\code{HIP_test_eval} returns a list with the following:
\item{\code{each}}{tensor(double) - (for gaussian outcomes) tensor of MSEs for each of the q outcomes}
\item{\code{comp_val}}{tensor(double) - MSE for gaussian outcomes, classification accuracy for multiclass outcomes, fraction of deviance explained for poisson/ZIP outcomes}
\item{\code{pred}}{list<tensor(double) - predicted values from fitted model. For multiclass outcomes, single integer to represent class, starting with 0. For poisson/ZIP, predicted means from fitted model}
\item{\code{dev_sum}}{list(tensor(double)) - (for poisson/ZIP outcomes), list with more detailed deviance information}
Also returns a histogram plot for predicted vs. true values in each subgroup.
}
\description{
\code{HIP_test_eval} is used to get model performance metrics (e.g. MSE or classification accuracy)
on test data. It can be used with models generated by \code{select_lambda} or \code{fixed_lambda}.
}
\examples{
# Generate data
dat_gen_test <- generate_data(test_data=TRUE)

# Get results from select_lambda
res <- select_lambda(dat_gen_test$X, dat_gen_test$Y, c(1,1), 'gaussian', 50,
                     K = 2, num_steps=c(4,4))

# Evaluating on test data
test_eval <- HIP_test_eval(dat_gen_test, res, 'search')

}
