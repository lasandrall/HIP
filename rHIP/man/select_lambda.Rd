% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/select_lambda.R
\name{select_lambda}
\alias{select_lambda}
\title{Fit HIP models across multiple lambda values}
\usage{
select_lambda(X, Y, gamma, family, topn, ncore=NA, K=NULL, k_thresh=0.2, update_thresh=10^-5,
              epsilon=10^-4, max_iter=50, search="random", xi_range=c(0,2),
              g_range=c(0,2), num_steps=c(8,8), standardize="subgroup",
              std_type="scale_center", std_x=TRUE, std_y=TRUE, verbose=FALSE,
              selection_criterion="eBIC_0", folds=5)
}
\arguments{
\item{X}{matrix list - list of X^d,s matrices containing covariates}

\item{Y}{matrix list - list of Y^s matrices containing outcomes}

\item{gamma}{list\if{html}{\out{<double>}} - indicators of whether to penalize each data view; should be length D}

\item{family}{string - family of outcome; options are 'gaussian', 'multiclass', 'poisson' or 'zip'}

\item{topn}{int or list\if{html}{\out{<int>}} - number of variables to retain; different values may be specified for each view using a list of length D}

\item{ncore}{int - number of cores to use in parallel processing; default is half of available cores}

\item{K}{int - number of latent components; will use 'select_K_simple' to choose if not provided}

\item{k_thresh}{\itemize{
\item double - threshold to use for 'select_K_simple' if K not provided; default = 0.2
}}

\item{epsilon}{double - threshold to use for overall convergence criterion; default = 10**-4}

\item{max_iter}{int - maximum number of outer loop iterations; default = 50}

\item{search}{string - what type of search to perform for lambda parameter; default = "random"
\itemize{
\item "random" - tries a random selection of rand_prop*num_steps lambda values in grid
\item "grid" - tries all lambda values in grid
}}

\item{xi_range}{list\if{html}{\out{<double>}} - minimum  and maximum values to consider for lambda_xi; default = \code{c(0.0, 2.0)}}

\item{g_range}{list\if{html}{\out{<double>}} - minimum  and maximum values to consider for lambda_g; default = \code{c(0.0, 2.0)}}

\item{num_steps}{list\if{html}{\out{<int>}} - list of two integers; the first is the number of steps for lambda_xi (default = 8) and the second is the number of steps for
lambda_g. Together these define the number of steps to use in lambda grid}

\item{standardize}{string - One of "all", "subgroup", or "none"; default = "subgroup"}

\item{std_type}{string - One of "scale_center", "center", or "norm"; default = "scale_center"}

\item{std_x}{boolean - indicates whether to standardize X; default = True}

\item{std_y}{boolean - indicates whether to standardize Y; default = True}

\item{verbose}{whether to print additional information during optimization; default = False}

\item{selection_criterion}{string - criterion to use for selecting the best model; one of 'CV', 'BIC', 'AIC', 'eBIC_0', 'eBIC_5', or 'eBIC_1'. eBIC_0 by default.}

\item{folds}{int - number of folds to use if CV is selected as the selection criterion; default = 5}
}
\value{
The output is quite large, but most items do not need to be accessed directly by the user and instead are accessed by functions such as \code{HIP_train_eval}
or \code{HIP_pred}. First, \code{select_lambda} returns a nested list called \code{out} which contains the following:
\item{\code{search_results}}{list - list with results returned from the optimize_torch Python function for each lambda value tried (see below for detailed output information)}
\item{\code{total_time}}{double - time to complete entire search in seconds}
\item{\code{xi_range}}{list\if{html}{\out{<double>}} - minimum and maximum values considered for lambda_xi}
\item{\code{g_range}}{list\if{html}{\out{<double>}} - minimum and maximum values considered for lambda_g}
\item{\code{num_steps}}{dict - number of steps used in lambda grid}
\item{\code{search}}{string - type of search performed for selecting lambda parameters }

select_lambda also returns the following:
\item{\code{best_index}}{int - index of the best model chosen by the selection criterion }
\item{\code{criterion}}{string - criterion for model selection: one of 'CV', 'BIC', 'AIC', 'eBIC_0', 'eBIC_5', or 'eBIC_1'. eBIC_0 by default.}
\item{\code{topn}}{int or list\if{html}{\out{<int>}} - number of variables retained}
\item{\code{standardize}}{string - stores option used to standardize data}
\item{\code{family}}{string - stores family label for outcome data}

\code{search_results} is a large list containing results from fit models. First, it contains
multiple fit models which have the following items:
\item{\code{full}}{list - results returned from optimize_torch on full data}
\item{\code{include}}{list\if{html}{\out{<tensor>}} - list of length D with a 1 indicating the variable was included in subset fit and 0 indicating not included in subset fit}
\item{\code{subset}}{list - results returned from optimize_torch on subset of variables}

\code{full} and \code{subset} are large lists which contain the following:
\item{\code{theta}}{tensor\if{html}{\out{<double>}} - estimate of theta}
\item{\code{beta}}{tensor\if{html}{\out{<double>}} - estimate of beta }
\item{\code{B}}{list<tensor\if{html}{\out{<double>}}> - estimates of each B^d,s}
\item{\code{G}}{list<tensor\if{html}{\out{<double>}}> - estimates of each G^d}
\item{\code{Xi}}{list<tensor\if{html}{\out{<double>}}> - estimates of each Xi^d,s}
\item{\code{Z}}{list<tensor\if{html}{\out{<double>}}> - estimates of each Z^s}
\item{\code{Lambda}}{tuple - values of lambda_xi and lambda_g used}
\item{\code{BIC}}{double - calculated BIC}
\item{\code{AIC}}{double - calculated AIC}
\item{\code{pred}}{double - prediction loss evaluated at final estimates}
\item{\code{train_err}}{nested list - list returned from function to calculate training error}
\item{\code{message}}{string - message with the status of the result; "Converged" if converged successfully, "MAX ITERS" if algorithm reached max_iter without converging.}
\item{\code{paths}}{list - history of losses until convergence}
\item{\code{iter}}{int - number of iterations to converge}
\item{\code{iter_time}}{double - time to find solution in seconds}
\item{\code{conv_criterion}}{double -  value of last convergence criterion}
\item{\code{std_x}}{boolean - whether X was standardized}
\item{\code{std_y}}{boolean - whether Y was standardized}
}
\description{
\code{select_lambda} searches across lambda values (either grid search or random) and fits HIP models
given training data. The best model is chosen based on selection criteria such as cross-validation,
BIC, or AIC. Results can then be used for model evaluation, prediction, and plotting.
}
\examples{
dat_gen <- generate_data()

res <- select_lambda(dat_gen$X, dat_gen$Y, c(1,1), 'gaussian', 50)

}
